name: Model Deploy Workflow

on:
  push:
    branches:
      - deploy/data
      - main

jobs:
  preprocess_and_upload:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/deploy/data'
    steps:
      # 1. 코드 체크아웃
      - name: Checkout code
        uses: actions/checkout@v2

      # 2. 현재 브랜치 확인
      - name: Check branch
        run: |
          echo "Running on branch: ${GITHUB_REF#refs/heads/}"
          if [[ "${GITHUB_REF#refs/heads/}" != "main" && "${GITHUB_REF#refs/heads/}" != "feature/cicd" && "${GITHUB_REF#refs/heads/}" != "deploy/data" ]]; then
            echo "This workflow can only be run on the 'main', 'feature/cicd', or 'deploy/data' branches."
            exit 1
          fi

      # 3. Python 설치
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.11

      # 3. 필요한 패키지 설치
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r LongTermTravelPlanner/requirements.txt
          pip install boto3

      # 4. 전처리 과정 실행 (preprocess.py)
      - name: Preprocess data
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_PUBLIC_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_PRIVATE_KEY }}
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
        run: |
          python LongTermTravelPlanner/src/preprocess.py

      # 5. 전처리된 파일 존재 확인
      - name: Verify processed train data file exists
        run: |
          ls -al LongTermTravelPlanner/data/processed/processed_train_data.csv

      # 6. S3로 전처리된 파일 업로드
      - name: Upload processed data to S3
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_PUBLIC_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_PRIVATE_KEY }}
          AWS_DEFAULT_REGION: ap-northeast-2
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
        run: |
          aws s3 cp LongTermTravelPlanner/data/processed/processed_train_data.csv s3://$S3_BUCKET_NAME/LongTermDataFrame/data/processed/processed_train_data.csv
          aws s3 cp LongTermTravelPlanner/data/processed/processed_test_data.csv s3://$S3_BUCKET_NAME/LongTermDataFrame/data/processed/processed_test_data.csv

  # 배포 작업
  deploy:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      # 1. 코드 체크아웃
      - name: Checkout code
        uses: actions/checkout@v2

      # 2. Python 설치
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.11

      # 3. 필요한 패키지 설치
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r LongTermTravelPlanner/requirements.txt
          pip install boto3

      # 4. 실제 배포 과정 (예: Docker 빌드 및 EC2로 배포)
      - name: Deploy to EC2
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_PUBLIC_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_PRIVATE_KEY }}
        run: |
          # 여기에 실제 배포 스크립트를 추가하세요

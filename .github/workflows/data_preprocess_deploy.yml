name: Model Deploy Workflow

on:
  push:
    branches:
      - feature/data
      - main

jobs:
  # 데이터 전처리 작업
  preprocess:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/feature/data' || github.ref == 'refs/heads/main'
    steps:
      # 1. 코드 체크아웃
      - name: Checkout code
        uses: actions/checkout@v2

      # 2. Python 설치
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.11

      # 3. 필요한 패키지 설치
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r LongTermTravelPlanner/requirements.txt
          pip install boto3

      # 4. 전처리 과정 실행 (preprocess.py)
      - name: Preprocess data
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_PUBLIC_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_PRIVATE_KEY }}
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
        run: |
          python LongTermTravelPlanner/src/preprocess.py

      # 5. 전처리된 파일 존재 확인
      - name: Verify processed train data file exists
        run: |
          ls -al LongTermTravelPlanner/data/processed/processed_train_data.csv

  # 배포 작업
  deploy:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      # 1. 코드 체크아웃
      - name: Checkout code
        uses: actions/checkout@v2

      # 2. 배포 트리거 조건 확인 (특정 파일 변경 확인)
      - name: Check if processed data has changed
        id: check_files
        run: |
          git diff --name-only HEAD^ HEAD | grep -E "LongTermTravelPlanner/data/processed/processed_train_data.csv|LongTermTravelPlanner/data/processed/processed_test_data.csv" || exit 1

      # 3. Python 설치
      - name: Set up Python
        if: success()
        uses: actions/setup-python@v2
        with:
          python-version: 3.11

      # 4. 필요한 패키지 설치
      - name: Install dependencies
        if: success()
        run: |
          pip install --upgrade pip
          pip install -r LongTermTravelPlanner/requirements.txt
          pip install boto3

      # 5. S3로 전처리된 파일 업로드 후 종료
      - name: Upload processed data to S3
        if: success()
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_PUBLIC_KEY }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_PRIVATE_KEY }}
          AWS_DEFAULT_REGION: ap-northeast-2
          S3_BUCKET_NAME: ${{ secrets.S3_BUCKET_NAME }}
        run: |
          aws s3 cp LongTermTravelPlanner/data/processed/processed_train_data.csv s3://$S3_BUCKET_NAME/LongTermDataFrame/data/processed/processed_train_data.csv
          aws s3 cp LongTermTravelPlanner/data/processed/processed_test_data.csv s3://$S3_BUCKET_NAME/LongTermDataFrame/data/processed/processed_test_data.csv
